---
cover:
  image: articles/NeuralNetwork.png

tags: ["Machine Learning","Neural networks"]

date: 2024-02-26

author: "Huzaif"
hideSummary: true
draft: true
---
Gordon Moore, co-founder of Intel, in 1965 observed that the number of transistors that could be packed onto an integrated circuit (IC) was doubling roughly every year. He later revised this to a doubling every two years.
![](/articles/Moore.png)
The pace of doubling has slowed significantly in recent years. We are still seeing improvements, but not strictly at the same rate as before. But new possibilities we have today from 10 years ago are reshaping the boundaries of what is possible.

## Machine Learning
- Supervised Learning
- Unsupervised Learning
- [Reinforcement Learning](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)











# Neural Networks
=Concept of tokens
A neuron can be thought of as a tiny little computer having only one job of taking input 'x' and output a single or multiple numbers 'a' 

A group of neurons is called a layer. A neural network is made up of:
- Input layer (layer 0)
- Hidden layers (activations)
- Output layer

You can think about neural networks as logistic regression unit using new better set of features for output

